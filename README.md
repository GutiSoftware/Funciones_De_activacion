# Funciones_De_activacion
Comparación de funciones de activación nuevas (Custom) con funciones de activacion estandard.

 El script principal (Funciones_Activacion.py) está diseñado para comparar diferentes funciones de activación en una red
 neuronal convolucional (CNN) utilizando el conjunto de datos MNIST de dígitos escritos a mano. 
 
 El objetivo es evaluar el rendimiento de las funciones de activación estandard ReLU, Sigmoid y Tanh, con funciones de
 activación personalizadas (Custom), guardando los resultados en unos archivos gráficos .png y .JSON en una
 carpeta llamada "Resultados"
 
 El Script: Tabla_Comparativa_Modelos.py hace una comparacion de los resultados obtenidos por el script anterior
 guardando los resultados en formato .csv
 
 Se puede evaluar cualquier funcione Custom dejandola sin comentar en el script. Ahora mismo se evalua la función Custom: WaveSoft
 y se dejan comentadas otras varias para que se pueda observar el formato que acepta el script.
